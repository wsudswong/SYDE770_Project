{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-Lightning with Weights & Biases.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wsudswong/SYDE770_Project/blob/main/Pytorch_Lightning_with_Weights_%26_Biases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FplHOfK2094n"
      },
      "source": [
        "!pip install -qqq wandb\n",
        "!pip install -qqq pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9AO80L80smw"
      },
      "source": [
        "# Weights & Biases\n",
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "# Pytorch modules\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Pytorch-Lightning\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Dataset\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXtU8qhm1oAr"
      },
      "source": [
        "class LitMNIST(LightningModule):\n",
        "\n",
        "    def __init__(self, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3):\n",
        "        # (2) HIDDEN LAYER SIZE\n",
        "        # (4) LEARNING RATE\n",
        "        '''method used to define our model parameters'''\n",
        "        super().__init__()\n",
        "\n",
        "        # mnist images are (1, 28, 28) (channels, width, height)\n",
        "        self.layer_1 = torch.nn.Linear(28 * 28, n_layer_1)\n",
        "        self.layer_2 = torch.nn.Linear(n_layer_1, n_layer_2)\n",
        "        self.layer_3 = torch.nn.Linear(n_layer_2, n_classes)\n",
        "\n",
        "        # optimizer parameters\n",
        "        self.lr = lr\n",
        "\n",
        "        # metrics\n",
        "        self.accuracy = nn.torchmetrics.accuracy()\n",
        "\n",
        "        # optional - save hyper-parameters to self.hparams\n",
        "        # they will also be automatically logged as config parameters in W&B\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''method used for inference input -> output'''\n",
        "\n",
        "        batch_size, channels, width, height = x.size()\n",
        "\n",
        "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.layer_1(x)\n",
        "        x = F.relu(x) # (3) ACTIVATION FUNCTION ReLU hidden\n",
        "        x = self.layer_2(x)\n",
        "        x = F.relu(x) # (3) ACTIVATION FUNCTION ReLU hidden\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        x = F.log_softmax(x, dim=1) # (3) ACTIVATION FUNCTION softmax output\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        '''needs to return a loss from a single batch'''\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        # Log training loss\n",
        "        self.log('train_loss', loss)\n",
        "\n",
        "        # Log metrics\n",
        "        #self.log('train_acc', self.accuracy(logits, y))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        '''used for logging metrics'''\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        # Log validation loss (will be automatically averaged over an epoch)\n",
        "        self.log('valid_loss', loss)\n",
        "\n",
        "        # Log metrics\n",
        "        #self.log('valid_acc', self.accuracy(logits, y))\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        '''used for logging metrics'''\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        # Log test loss\n",
        "        self.log('test_loss', loss)\n",
        "\n",
        "        # Log metrics\n",
        "        #self.log('test_acc', self.accuracy(logits, y))\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        '''defines model optimizer'''\n",
        "        return Adam(self.parameters(), lr=self.lr) # (7) OPTIMIZER"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6EvnEfK65ML"
      },
      "source": [
        "class MNISTDataModule(LightningDataModule):\n",
        "\n",
        "    def __init__(self, data_dir='./', batch_size=256):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        '''called only once and on 1 GPU'''\n",
        "        # download data\n",
        "        MNIST(self.data_dir, train=True, download=True)\n",
        "        MNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        '''called on each GPU separately - stage defines if we are at fit or test step'''\n",
        "        # we set up only relevant datasets when stage is specified (automatically set by Pytorch-Lightning)\n",
        "        if stage == 'fit' or stage is None:\n",
        "            mnist_train = MNIST(self.data_dir, train=True, transform=self.transform)\n",
        "            self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        '''returns training dataloader'''\n",
        "        mnist_train = DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
        "        return mnist_train\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        '''returns validation dataloader'''\n",
        "        mnist_val = DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
        "        return mnist_val\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        '''returns test dataloader'''\n",
        "        mnist_test = DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
        "        return mnist_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6fuJ6hq2ige"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI1Bh8CGI-FG"
      },
      "source": [
        "wandb_logger = WandbLogger(project='MNIST')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7zB4ObdI8u8"
      },
      "source": [
        "# setup data\n",
        "mnist = MNISTDataModule()\n",
        " \n",
        "# setup model - choose different hyperparameters per experiment\n",
        "model = LitMNIST(n_layer_1=128, n_layer_2=256, lr=1e-3) # (2) HIDDEN LAYER SIZE (4) LEARNING RATE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxXtBfFrKYgA"
      },
      "source": [
        "trainer = Trainer(\n",
        "    logger=wandb_logger,    # W&B integration\n",
        "    gpus=-1,                # use all GPU's\n",
        "    max_epochs=3            # number of epochs\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xSW1nrBWGem"
      },
      "source": [
        "trainer.fit(model, mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6dD01TpWP8G"
      },
      "source": [
        "trainer.test(model, datamodule=mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbxIU2ZoXzcQ"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_pd7aAW4DfM"
      },
      "source": [
        "sweep_config = {\n",
        "  \"method\": \"random\",   # Random search\n",
        "  \"metric\": {           # We want to maximize val_acc\n",
        "      \"name\": \"valid_acc\",\n",
        "      \"goal\": \"maximize\"\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \"n_layer_1\": {\n",
        "            # Choose from pre-defined values\n",
        "            \"values\": [32, 64, 128, 256, 512]\n",
        "        },\n",
        "        \"n_layer_2\": {\n",
        "            # Choose from pre-defined values\n",
        "            \"values\": [32, 64, 128, 256, 512]\n",
        "        },\n",
        "        \"lr\": {\n",
        "            # log uniform distribution between exp(min) and exp(max)\n",
        "            \"distribution\": \"log_uniform\",\n",
        "            \"min\": -9.21,   # exp(-9.21) = 1e-4\n",
        "            \"max\": -4.61    # exp(-4.61) = 1e-2\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U94DcCEF-gFN"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"MNIST\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27DZPzx-zK8k"
      },
      "source": [
        "def sweep_iteration():\n",
        "    # set up W&B logger\n",
        "    wandb.init()    # required to have access to `wandb.config`\n",
        "    wandb_logger = WandbLogger()\n",
        "\n",
        "    # setup data\n",
        "    mnist = MNISTDataModule()\n",
        "\n",
        "    # setup model - note how we refer to sweep parameters with wandb.config\n",
        "    model = LitMNIST(\n",
        "        n_layer_1=wandb.config.n_layer_1,\n",
        "        n_layer_2=wandb.config.n_layer_2,\n",
        "        lr=wandb.config.lr\n",
        "    )\n",
        "\n",
        "    # setup Trainer\n",
        "    trainer = Trainer(\n",
        "        logger=wandb_logger,    # W&B integration\n",
        "        gpus=-1,                # use all GPU's\n",
        "        max_epochs=3            # number of epochs\n",
        "        )\n",
        "\n",
        "    # train\n",
        "    trainer.fit(model, mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo2fOKC7BeKO"
      },
      "source": [
        "wandb.agent(sweep_id, function=sweep_iteration)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}